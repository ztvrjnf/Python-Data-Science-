{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score, learning_curve\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb, lightgbm as lgbm, catboost as catb\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "DATA_ROOT = Path('C:/Users/Sancho/Downloads/python 2/lesson 3/')\n",
    "MODELS_PATH = Path('./models/')\n",
    "\n",
    "# input\n",
    "DATASET_PATH = DATA_ROOT / 'train.csv'\n",
    "\n",
    "# output\n",
    "TRAIN_FULL_PATH = DATA_ROOT / 'training_project_train_full.csv'\n",
    "TRAIN_PART_PATH = DATA_ROOT / 'training_project_train_part_b.csv'\n",
    "TEST_PART_PATH = DATA_ROOT / 'training_project_test_part.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_train_true, y_train_pred, y_test_true, y_test_pred):\n",
    "    print('TRAIN\\n\\n' + classification_report(y_train_true, y_train_pred))\n",
    "    print('TEST\\n\\n' + classification_report(y_test_true, y_test_pred))\n",
    "    print('CONFUSION MATRIX\\n')\n",
    "    print(pd.crosstab(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(model, X_train, X_test, y_train, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    get_classification_report(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home Ownership</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Years in current job</th>\n",
       "      <th>Tax Liens</th>\n",
       "      <th>Number of Open Accounts</th>\n",
       "      <th>Years of Credit History</th>\n",
       "      <th>Maximum Open Credit</th>\n",
       "      <th>Number of Credit Problems</th>\n",
       "      <th>Months since last delinquent</th>\n",
       "      <th>Bankruptcies</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Term</th>\n",
       "      <th>Current Loan Amount</th>\n",
       "      <th>Current Credit Balance</th>\n",
       "      <th>Monthly Debt</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Credit Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Own Home</td>\n",
       "      <td>482087.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>685960.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>47386.0</td>\n",
       "      <td>7914.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Own Home</td>\n",
       "      <td>1025487.0</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1181730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>Long Term</td>\n",
       "      <td>264968.0</td>\n",
       "      <td>394972.0</td>\n",
       "      <td>18373.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home Mortgage</td>\n",
       "      <td>751412.0</td>\n",
       "      <td>8 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1182434.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>308389.0</td>\n",
       "      <td>13651.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Own Home</td>\n",
       "      <td>805068.0</td>\n",
       "      <td>6 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>147400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>121396.0</td>\n",
       "      <td>95855.0</td>\n",
       "      <td>11338.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rent</td>\n",
       "      <td>776264.0</td>\n",
       "      <td>8 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>385836.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>125840.0</td>\n",
       "      <td>93309.0</td>\n",
       "      <td>7180.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Home Ownership  Annual Income Years in current job  Tax Liens  \\\n",
       "0       Own Home       482087.0                  NaN        0.0   \n",
       "1       Own Home      1025487.0            10+ years        0.0   \n",
       "2  Home Mortgage       751412.0              8 years        0.0   \n",
       "3       Own Home       805068.0              6 years        0.0   \n",
       "4           Rent       776264.0              8 years        0.0   \n",
       "\n",
       "   Number of Open Accounts  Years of Credit History  Maximum Open Credit  \\\n",
       "0                     11.0                     26.3             685960.0   \n",
       "1                     15.0                     15.3            1181730.0   \n",
       "2                     11.0                     35.0            1182434.0   \n",
       "3                      8.0                     22.5             147400.0   \n",
       "4                     13.0                     13.6             385836.0   \n",
       "\n",
       "   Number of Credit Problems  Months since last delinquent  Bankruptcies  \\\n",
       "0                        1.0                           NaN           1.0   \n",
       "1                        0.0                           NaN           0.0   \n",
       "2                        0.0                           NaN           0.0   \n",
       "3                        1.0                           NaN           1.0   \n",
       "4                        1.0                           NaN           0.0   \n",
       "\n",
       "              Purpose        Term  Current Loan Amount  \\\n",
       "0  debt consolidation  Short Term           99999999.0   \n",
       "1  debt consolidation   Long Term             264968.0   \n",
       "2  debt consolidation  Short Term           99999999.0   \n",
       "3  debt consolidation  Short Term             121396.0   \n",
       "4  debt consolidation  Short Term             125840.0   \n",
       "\n",
       "   Current Credit Balance  Monthly Debt  Credit Score  Credit Default  \n",
       "0                 47386.0        7914.0         749.0               0  \n",
       "1                394972.0       18373.0         737.0               1  \n",
       "2                308389.0       13651.0         742.0               0  \n",
       "3                 95855.0       11338.0         694.0               0  \n",
       "4                 93309.0        7180.0         719.0               0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NAME = 'Credit Default'\n",
    "BASE_FEATURE_NAMES = df.columns.drop(TARGET_NAME).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURE_NAMES = ['Annual Income','Tax Liens','Number of Open Accounts','Years of Credit History','Maximum Open Credit',\n",
    "                     'Number of Credit Problems','Months since last delinquent','Bankruptcies','Current Credit Balance',\n",
    "                     'Monthly Debt','Credit Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCorrection:\n",
    "    def __init__(self, path_to_file):\n",
    "        \n",
    "        self.add_dummies_columns = None\n",
    "        self.df = pd.read_csv(path_to_file)\n",
    "        self.medians=None\n",
    "        \n",
    "    def fit(self, df):\n",
    "        self.medians = df.median()\n",
    "    \n",
    "    def fill(self):\n",
    "        df = self.df.copy()\n",
    "        add_dummies_columns = None\n",
    "\n",
    "        Term_to_nubmers = {'Short Term':'0', 'Long Term':'1'}\n",
    "        \n",
    "        Purpose_to_numbers = {'debt consolidation':'0', 'other':'1', 'home improvements':'2', 'business loan':'3',\n",
    "                              'buy a car':'3', 'medical bills':'3', 'major purchase':'3', 'take a trip':'1',\n",
    "                              'buy house':'1', 'small business':'1', 'wedding':'1', 'moving':'1',\n",
    "                              'educational expenses':'1', 'vacation':'1', 'renewable energy':'1'}\n",
    "        \n",
    "        Home_O_to_numbers = {'Home Mortgage':'0', 'Rent':'1', 'Own Home':'2', 'Have Mortgage':'0'}\n",
    "        \n",
    "        Job_Years_to_numbers = {'< 1 year':'0',\n",
    "                            '1 year':'1','2 years':'1','3 years':'1','4 years':'2','5 years':'2', \n",
    "                            '6 years':'2','7 years':'3','8 years':'3','9 years':'3',\n",
    "                            '10+ years':'4'}\n",
    "        \n",
    "        df.loc[df['Credit Score'] >= 3000, 'Credit Score'] = (df['Credit Score'] / 10)\n",
    "        df.loc[df['Current Loan Amount'] >= 9000000.0, 'Current Loan Amount'] = self.medians['Current Loan Amount']\n",
    "        \n",
    "        df['Annual Income'].fillna(self.medians['Annual Income'], inplace=True)\n",
    "        df['Home Ownership'].fillna('Rent', inplace=True)\n",
    "        df['Years in current job'].fillna('2 years', inplace=True)\n",
    "        df['Bankruptcies'].fillna(0.0, inplace=True)\n",
    "        df['Months since last delinquent'].fillna(self.medians['Months since last delinquent'], inplace=True)\n",
    "        df['Credit Score'].fillna(self.medians['Credit Score'], inplace=True)\n",
    "        df.loc[df['Bankruptcies'] >= 3, 'Bankruptcies'] = 3\n",
    "        df['Years in current job'] = df['Years in current job'].map(Job_Years_to_numbers)\n",
    "        df['Home Ownership'] = df['Home Ownership'].map(Home_O_to_numbers)\n",
    "        df['Purpose'] = df['Purpose'].map(Purpose_to_numbers)\n",
    "        df['Term'] = df['Term'].map(Term_to_nubmers)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = DataCorrection(DATASET_PATH)\n",
    "correction.fit(df)\n",
    "train_df=correction.fill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "df_norm = train_df.copy()\n",
    "df_norm[NUM_FEATURE_NAMES] = scaler.fit_transform(df_norm[NUM_FEATURE_NAMES])\n",
    "\n",
    "train_df = df_norm.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.718286\n",
       "1    0.281714\n",
       "Name: Credit Default, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.718222\n",
       "1    0.281778\n",
       "Name: Credit Default, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = train_df[BASE_FEATURE_NAMES]\n",
    "y = train_df[TARGET_NAME]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "display(y_train.value_counts(normalize=True), y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(TRAIN_FULL_PATH, index=False, encoding='utf-8')\n",
    "train.to_csv(TRAIN_PART_PATH, index=False, encoding='utf-8')\n",
    "test.to_csv(TEST_PART_PATH, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.36      0.51      3771\n",
      "           1       0.35      0.87      0.50      1479\n",
      "\n",
      "    accuracy                           0.50      5250\n",
      "   macro avg       0.61      0.61      0.50      5250\n",
      "weighted avg       0.73      0.50      0.51      5250\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.36      0.51      1616\n",
      "           1       0.34      0.84      0.49       634\n",
      "\n",
      "    accuracy                           0.50      2250\n",
      "   macro avg       0.60      0.60      0.50      2250\n",
      "weighted avg       0.71      0.50      0.50      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0     1\n",
      "Credit Default           \n",
      "0               588  1028\n",
      "1               100   534\n"
     ]
    }
   ],
   "source": [
    "model_tree = DecisionTreeClassifier(random_state=21,\n",
    "                                    class_weight={0:1, 1:3.6},\n",
    "                                    max_depth=4\n",
    "                                    )\n",
    "model_tree.fit(X_train, y_train)\n",
    "\n",
    "evaluate_preds(model_tree, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      3771\n",
      "           1       0.93      0.51      0.66      1479\n",
      "\n",
      "    accuracy                           0.85      5250\n",
      "   macro avg       0.89      0.75      0.78      5250\n",
      "weighted avg       0.86      0.85      0.84      5250\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83      1616\n",
      "           1       0.54      0.21      0.30       634\n",
      "\n",
      "    accuracy                           0.73      2250\n",
      "   macro avg       0.64      0.57      0.57      2250\n",
      "weighted avg       0.69      0.73      0.68      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1501  115\n",
      "1                501  133\n",
      "Wall time: 4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_catb = catb.CatBoostClassifier(silent=True, random_state=21)\n",
    "model_catb.fit(X_train, y_train)\n",
    "\n",
    "evaluate_preds(model_catb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Текстовая часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?\n",
    "# Weighted - вычисляет F1 для каждого класса отдельно, но при сложении этих значений каждое из них умножается на вес \n",
    "# класса который зависит от количества положительных результатов, тем самым отдавая предпочтение большим классам.\n",
    "# Macro - также вычилсяет F1 для каждого класса отдельно, но уже не добавляет вес к слагаемым, тем самым увеличивая \n",
    "# \"наказание\" за ошибку в малых классах \n",
    "# Micro - подсчитывает данные F1 (TP, FN, FP) для всех классов одноверменно не отдавая предпочтение ни одному из классов\n",
    "# Macro можно использовать при наличии больших и не менее важных малых выборок, к примеру как в курсовой, к которой\n",
    "# мы готовимся. Weighted будет использоваться для увеличения точности в нескольких основных классах, жертвуя точностью\n",
    "# оставшихся малых. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?\n",
    "# xgboost использует похожесть полученных \"листочков\" как аналог энтропии Шеннона для вычисления прироста инфрмации от \n",
    "# каждого производимого разбиения и задавая гиперпараметр лямбду мы можем настроить минимальный прирост информации от\n",
    "# производимых разбиений и тем самым улучшить защиту от переобучения. Из трех представленных, как мне показалось,\n",
    "# этот метод ближе всех к классическому градиентному бустингу.\n",
    "# Lightgbm - придумывался как более быстрая версия градиентного бустинга, где идет выборка по строкам и уменьшение(объединение)\n",
    "# признаков. Также он отличается способом построения дерева. В этом методе построение идет от \"листочков\" с \n",
    "# наибольшей ошибкой для быстрого уменьшения кол-ва ошибок\n",
    "# Особенность catboost в симметричности деревьев и за счет этого скорость обучения увеличивается в разы. Также у этой\n",
    "# модели есть встроенное предотвращение переобучения в виде перемешивания выборки и обучения нескольких моделей одновременно,\n",
    "# которые будут проверяться на данных которые они до этого не видели"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
